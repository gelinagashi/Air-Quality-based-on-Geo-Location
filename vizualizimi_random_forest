import pandas as pd
import numpy as np
from numpy import int64
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('preprocessed_air_quality.csv')

# Preprocess the dataset
data['Start_Date'] = pd.to_datetime(data['Start_Date'])
data['year'] = data['Start_Date'].dt.year
data['month'] = data['Start_Date'].dt.month
data['day'] = data['Start_Date'].dt.day

# One-hot encode categorical columns
data = pd.get_dummies(data, columns=['Name', 'Geo Type Name', 'Geo Place Name', 'Time Period'])

# Split the dataset into features and target variable
X = data.drop('Data Value', axis=1)
X['Start_Date'] = pd.to_datetime(X['Start_Date']).astype(int64) / 10**9
y = data['Data Value']

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions and evaluate the model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print('The shape of our features is:', data.shape)

# Descriptive statistics for each column
desc_stats = data.describe()

# Print the table of columns
print("Table of columns:")
for col in desc_stats.columns:
    print(f"{col}")

# Plot feature importance
feature_importances = model.feature_importances_
feature_names = X.columns
sorted_indices = np.argsort(feature_importances)

plt.figure(figsize=(10, 6))
plt.barh(range(len(feature_names)), feature_importances[sorted_indices], align='center')
plt.yticks(range(len(feature_names)), np.array(feature_names)[sorted_indices])
plt.xlabel('Feature Importance')
plt.title('Random Forest: Feature Importance')
plt.show()
